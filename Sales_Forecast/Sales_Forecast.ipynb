{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c35f3c-0bdc-4768-837c-5433614c1b88",
      "metadata": {
        "id": "b9c35f3c-0bdc-4768-837c-5433614c1b88"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_time_features(df):\n",
        "    df['OutDate'] = pd.to_datetime(df['OutDate'])\n",
        "    df['Sales'] = df['Sales'].astype('category')\n",
        "    df['Customer'] = df['Customer'].astype('category')\n",
        "    df['Product'] = df['Product'].astype('category')\n",
        "    df['ProductID'] = df['ProductID'].astype('category')\n",
        "    df['Year'] = df['OutDate'].dt.year\n",
        "    df['Month'] = df['OutDate'].dt.month\n",
        "    df['Day'] = df['OutDate'].dt.day\n",
        "    df['Weekday'] = df['OutDate'].dt.weekday\n",
        "    return df"
      ],
      "metadata": {
        "id": "Nz4ApstFmnul"
      },
      "id": "Nz4ApstFmnul",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation\n"
      ],
      "metadata": {
        "id": "tUcTLKpaZVf5"
      },
      "id": "tUcTLKpaZVf5"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Sales_Summary.csv')\n",
        "\n",
        "df = add_time_features(df)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "bJe8n9BQLpUZ"
      },
      "id": "bJe8n9BQLpUZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3CHASY_CJStR"
      },
      "id": "3CHASY_CJStR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "odIhogHmKrtc"
      },
      "id": "odIhogHmKrtc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Year and Weekday\n",
        "grouped_data = df.groupby(['Year', 'Weekday'])['TotalSales'].sum().reset_index()\n",
        "\n",
        "# Mapping numbers to weekday names\n",
        "weekday_map = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday',\n",
        "               4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
        "\n",
        "grouped_data['Weekday'] = grouped_data['Weekday'].map(weekday_map)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Get unique years\n",
        "years = grouped_data['Year'].unique()\n",
        "\n",
        "for year in years:\n",
        "    # Filter data for each year\n",
        "    yearly_data = grouped_data[grouped_data['Year'] == year]\n",
        "\n",
        "    # Plot\n",
        "    sns.lineplot(x='Weekday', y='TotalSales', data=yearly_data, label=str(year))\n",
        "\n",
        "plt.title('Total Sales by Weekday for Each Year')\n",
        "plt.xlabel('Weekday')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Year')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5E9LD6hDtIfZ"
      },
      "id": "5E9LD6hDtIfZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_data = df.groupby(['Year', 'Month'])['TotalSales'].sum().reset_index()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Get unique years\n",
        "years = grouped_data['Year'].unique()\n",
        "\n",
        "for year in years:\n",
        "    # Filter data for each year\n",
        "    yearly_data = grouped_data[grouped_data['Year'] == year]\n",
        "\n",
        "    # Plot\n",
        "    sns.lineplot(x='Month', y='TotalSales', data=yearly_data, label=str(year))\n",
        "\n",
        "plt.title('Total Sales by Month for Each Year')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Year')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cd1TW925spbN"
      },
      "id": "cd1TW925spbN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of dimensions for which you want to plot summaries\n",
        "dimensions = ['Year', 'Month', 'Day', 'Weekday', 'Sales']\n",
        "\n",
        "for dimension in dimensions:\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    ax = sns.barplot(x=dimension, y='TotalSales', data=df, estimator=lambda x: sum(x) / 1e6, ci=None)\n",
        "\n",
        "    # Format y-axis in millions\n",
        "    ax.set_ylabel('Total Sales (in Millions)')\n",
        "    ax.set_yticklabels([f'{y:.1f}M' for y in ax.get_yticks()])\n",
        "\n",
        "    # Add labels on each bar\n",
        "    for p in ax.patches:\n",
        "        ax.annotate(f'{p.get_height():.1f}M',  # Format the label in millions\n",
        "                    (p.get_x() + p.get_width() / 2., p.get_height()),  # Position for the label\n",
        "                    ha='center', va='center',  # Alignment\n",
        "                    xytext=(0, 10),  # Distance from the bar\n",
        "                    textcoords='offset points')\n",
        "\n",
        "    plt.title(f'Total Sales by {dimension}')\n",
        "    plt.xticks(rotation=45)  # Rotate labels for better readability if needed\n",
        "    plt.xlabel(dimension)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1E0TyhSLm-4s"
      },
      "id": "1E0TyhSLm-4s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['YearMonth'] = df['OutDate'].dt.to_period('M')\n",
        "sales_categories = df['Sales'].unique()\n",
        "\n",
        "# Set the size of the plots\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Loop through each sales category and plot\n",
        "for sales_category in sales_categories:\n",
        "    # Filter data for the current category\n",
        "    category_data = df[df['Sales'] == sales_category]\n",
        "\n",
        "    # Group by YearMonth and sum the TotalSales\n",
        "    grouped_data = category_data.groupby('YearMonth')['TotalSales'].sum().reset_index()\n",
        "\n",
        "    # Plot\n",
        "    plt.plot(grouped_data['YearMonth'].dt.to_timestamp(), grouped_data['TotalSales'], label=sales_category)\n",
        "\n",
        "# Add plot details\n",
        "plt.title('Total Sales by Sales Category Over Time')\n",
        "plt.xlabel('Year-Month')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Sales Category')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0974060n0gi5"
      },
      "id": "0974060n0gi5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "zrsEPB4k0s1x"
      },
      "id": "zrsEPB4k0s1x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_sales_df = df.groupby('OutDate')['TotalSales'].sum().reset_index()\n",
        "total_sales_df"
      ],
      "metadata": {
        "id": "Hb4BWLuE9buw"
      },
      "id": "Hb4BWLuE9buw",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "def _plot_series(series, series_name, series_index=0):\n",
        "  from matplotlib import pyplot as plt\n",
        "  import seaborn as sns\n",
        "  palette = list(sns.palettes.mpl_palette('Dark2'))\n",
        "  xs = series['OutDate']\n",
        "  ys = series['TotalSales']\n",
        "\n",
        "  plt.plot(xs, ys, label=series_name, color=palette[series_index % len(palette)])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 5.2), layout='constrained')\n",
        "df_sorted = total_sales_df.sort_values('OutDate', ascending=True)\n",
        "_plot_series(df_sorted, '')\n",
        "sns.despine(fig=fig, ax=ax)\n",
        "plt.xlabel('OutDate')\n",
        "_ = plt.ylabel('TotalSales')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "9iiYyA_KZ1W6"
      },
      "id": "9iiYyA_KZ1W6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate data for forecast by Sales category\n",
        "sales_category_df = df.groupby(['OutDate', 'Sales'])['TotalSales'].sum().reset_index()\n",
        "sales_category_df"
      ],
      "metadata": {
        "id": "0Qx-meYH9gj4"
      },
      "id": "0Qx-meYH9gj4",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 5.2), layout='constrained')\n",
        "\n",
        "# Get unique sales categories\n",
        "sales_categories = sales_category_df['Sales'].unique()\n",
        "\n",
        "# Plot each category\n",
        "for index, category in enumerate(sales_categories):\n",
        "    category_df = sales_category_df[sales_category_df['Sales'] == category].sort_values('OutDate', ascending=True)\n",
        "    _plot_series(category_df, category, series_index=index)\n",
        "\n",
        "# Finalize the plot\n",
        "sns.despine(fig=fig, ax=ax)\n",
        "plt.xlabel('OutDate')\n",
        "plt.ylabel('TotalSales')\n",
        "plt.legend(title='Sales Category')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "HOfTnMmaaecm"
      },
      "id": "HOfTnMmaaecm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering"
      ],
      "metadata": {
        "id": "NqLmhwGKZemG"
      },
      "id": "NqLmhwGKZemG"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "total_sales_df = add_time_features(total_sales_df)\n",
        "sales_category_df = add_time_features(sales_category_df)\n",
        "total_sales_df"
      ],
      "metadata": {
        "id": "1vMis2cB9jtu"
      },
      "id": "1vMis2cB9jtu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_category_df"
      ],
      "metadata": {
        "id": "ixynG7vp9oHV"
      },
      "id": "ixynG7vp9oHV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-Test Split"
      ],
      "metadata": {
        "id": "qlHn0qPYZh59"
      },
      "id": "qlHn0qPYZh59"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a split date as a Timestamp object\n",
        "split_date = pd.Timestamp('2023-01-01')\n",
        "\n",
        "# For total forecast\n",
        "train_total = total_sales_df[total_sales_df['OutDate'] < split_date]\n",
        "test_total = total_sales_df[total_sales_df['OutDate'] >= split_date]\n",
        "\n",
        "# For Sales category forecast\n",
        "train_sales_category = sales_category_df[sales_category_df['OutDate'] < split_date]\n",
        "# train_sales_category = train_data.asfreq('D', fill_value=0)\n",
        "\n",
        "test_sales_category = sales_category_df[sales_category_df['OutDate'] >= split_date]\n",
        "\n",
        "train_total.shape, test_total.shape, train_sales_category.shape, test_sales_category.shape"
      ],
      "metadata": {
        "id": "afpiKo969tdd"
      },
      "id": "afpiKo969tdd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training"
      ],
      "metadata": {
        "id": "g08KTb1X-r5A"
      },
      "id": "g08KTb1X-r5A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. Total Forecast Model\n"
      ],
      "metadata": {
        "id": "fEWKs1y4-z75"
      },
      "id": "fEWKs1y4-z75"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the data\n",
        "X_train_total = train_total.drop(['TotalSales', 'OutDate'], axis=1)\n",
        "y_train_total = train_total['TotalSales']\n",
        "\n",
        "X_test_total = test_total.drop(['TotalSales', 'OutDate'], axis=1)\n",
        "y_test_total = test_total['TotalSales']\n",
        "\n",
        "# Train the model\n",
        "model_total = LinearRegression()\n",
        "model_total.fit(X_train_total, y_train_total)"
      ],
      "metadata": {
        "id": "EQqkOeh99xX8"
      },
      "id": "EQqkOeh99xX8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Ensure 'OutDate' is the index and the data is sorted\n",
        "# train_total = train_total.set_index('OutDate').sort_index()\n",
        "# test_total = test_total.set_index('OutDate').sort_index()\n",
        "\n",
        "# Set the frequency of the datetime index\n",
        "train_total.index = pd.DatetimeIndex(train_total.index).to_period('D')\n",
        "test_total.index = pd.DatetimeIndex(test_total.index).to_period('D')\n",
        "\n",
        "# Define and fit the SARIMA model - example parameters, adjust based on your data\n",
        "model_total = sm.tsa.statespace.SARIMAX(train_total['TotalSales'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
        "results_total = model_total.fit()"
      ],
      "metadata": {
        "id": "KmwFSe1KfuUG"
      },
      "id": "KmwFSe1KfuUG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. Sales Category Forecast Model\n"
      ],
      "metadata": {
        "id": "gnKOeEaG-3hU"
      },
      "id": "gnKOeEaG-3hU"
    },
    {
      "cell_type": "code",
      "source": [
        "models_by_sales = {}\n",
        "\n",
        "for sales_category in train_sales_category['Sales'].unique():\n",
        "    train_data = train_sales_category[train_sales_category['Sales'] == sales_category]\n",
        "    X_train = train_data.drop(['TotalSales', 'OutDate', 'Sales'], axis=1)\n",
        "    y_train = train_data['TotalSales']\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    models_by_sales[sales_category] = model\n"
      ],
      "metadata": {
        "id": "7q4Un4mB9wHd"
      },
      "id": "7q4Un4mB9wHd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_by_sales = {}\n",
        "\n",
        "for sales_category in train_sales_category['Sales'].unique():\n",
        "    train_data = train_sales_category[train_sales_category['Sales'] == sales_category]\n",
        "    train_data.index = pd.DatetimeIndex(train_data.index).to_period('M')\n",
        "\n",
        "    # Define and fit the SARIMA model for each category\n",
        "    model = sm.tsa.statespace.SARIMAX(train_data['TotalSales'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
        "    results = model.fit()\n",
        "    models_by_sales[sales_category] = results"
      ],
      "metadata": {
        "id": "snp-jxIbfzLi"
      },
      "id": "snp-jxIbfzLi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation\n"
      ],
      "metadata": {
        "id": "L4z11d_s_Auo"
      },
      "id": "L4z11d_s_Auo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. Total Forecast Model Evaluation\n"
      ],
      "metadata": {
        "id": "nSHF9HkQ_PLM"
      },
      "id": "nSHF9HkQ_PLM"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_total = model_total.predict(X_test_total)\n",
        "mse_total = mean_squared_error(y_test_total, y_pred_total)\n",
        "print(f'Total Forecast MSE: {mse_total}')"
      ],
      "metadata": {
        "id": "DwJHHcPu_KAV"
      },
      "id": "DwJHHcPu_KAV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. Sales Category Forecast Model Evaluation\n"
      ],
      "metadata": {
        "id": "LauxEKFG_U8A"
      },
      "id": "LauxEKFG_U8A"
    },
    {
      "cell_type": "code",
      "source": [
        "mse_by_sales = {}\n",
        "\n",
        "for sales_category, model in models_by_sales.items():\n",
        "    test_data = test_sales_category[test_sales_category['Sales'] == sales_category]\n",
        "    X_test = test_data.drop(['TotalSales', 'OutDate', 'Sales'], axis=1)\n",
        "    y_test = test_data['TotalSales']\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mse_by_sales[sales_category] = mse\n",
        "\n",
        "for sales_category, mse in mse_by_sales.items():\n",
        "    print(f'{sales_category} Forecast MSE: {mse}')\n"
      ],
      "metadata": {
        "id": "UvrR0KOR_Fgd"
      },
      "id": "UvrR0KOR_Fgd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forecasting\n"
      ],
      "metadata": {
        "id": "eZTXWCwk_bGY"
      },
      "id": "eZTXWCwk_bGY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating Future Dates"
      ],
      "metadata": {
        "id": "VXJKllba_-PM"
      },
      "id": "VXJKllba_-PM"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a date range for 2024, assuming monthly forecasts\n",
        "future_dates = pd.date_range(start='2023-11-08', end='2024-12-31', freq='MS')\n",
        "future_dates_df = pd.DataFrame(future_dates, columns=['OutDate'])\n",
        "\n",
        "# Add additional time features if they were used in the model\n",
        "future_dates_df['Year'] = future_dates_df['OutDate'].dt.year\n",
        "future_dates_df['Month'] = future_dates_df['OutDate'].dt.month\n",
        "future_dates_df['Day'] = future_dates_df['OutDate'].dt.day\n",
        "future_dates_df['Weekday'] = future_dates_df['OutDate'].dt.weekday"
      ],
      "metadata": {
        "id": "6aZaf4ZGACu0"
      },
      "id": "6aZaf4ZGACu0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. Total Forecast\n"
      ],
      "metadata": {
        "id": "QMeTQEl9_d0h"
      },
      "id": "QMeTQEl9_d0h"
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop 'OutDate' as it was not used in the model\n",
        "X_future_total = future_dates_df.drop(['OutDate'], axis=1)\n",
        "\n",
        "# Make predictions\n",
        "future_total_sales_predictions = model_total.predict(X_future_total)\n",
        "\n",
        "# Combine predictions with dates for better readability\n",
        "total_forecast = pd.DataFrame({\n",
        "    'Date': future_dates_df['OutDate'],\n",
        "    'Predicted Total Sales': future_total_sales_predictions\n",
        "})"
      ],
      "metadata": {
        "id": "jYRiqpUbACMx"
      },
      "id": "jYRiqpUbACMx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. Sales Category Forecast\n"
      ],
      "metadata": {
        "id": "GxRhQw5U_lDu"
      },
      "id": "GxRhQw5U_lDu"
    },
    {
      "cell_type": "code",
      "source": [
        "future_sales_predictions = {}\n",
        "\n",
        "for sales_category in train_sales_category['Sales'].unique():\n",
        "    # Create a DataFrame for each category\n",
        "    future_df = future_dates_df.copy()\n",
        "    future_df['Sales'] = sales_category  # Add the sales category\n",
        "\n",
        "    # Add any other necessary features or transformations\n",
        "\n",
        "    # Prepare the data for the model\n",
        "    X_future = future_df.drop(['OutDate', 'Sales'], axis=1)\n",
        "\n",
        "    # Make predictions\n",
        "    model = models_by_sales[sales_category]\n",
        "    future_sales_predictions[sales_category] = model.predict(X_future)\n",
        "\n",
        "    # Combine predictions with dates\n",
        "    future_sales_predictions[sales_category] = pd.DataFrame({\n",
        "        'Date': future_dates_df['OutDate'],\n",
        "        'Predicted Sales for ' + sales_category: future_sales_predictions[sales_category]\n",
        "    })\n"
      ],
      "metadata": {
        "id": "njxmry1S_nN0"
      },
      "id": "njxmry1S_nN0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting"
      ],
      "metadata": {
        "id": "dhcs2WR7AZ-Q"
      },
      "id": "dhcs2WR7AZ-Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. Plot actual and forecasted for Total"
      ],
      "metadata": {
        "id": "M-DE3GpUBJzS"
      },
      "id": "M-DE3GpUBJzS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Historical data (up to 2023)\n",
        "historical_sales_df = total_sales_df\n",
        "historical_sales_df['OutDate'] = pd.to_datetime(historical_sales_df['OutDate'])\n",
        "historical_sales_df = historical_sales_df.sort_values('OutDate')\n",
        "\n",
        "# Forecasted data (for 2024)\n",
        "total_forecast['Date'] = pd.to_datetime(total_forecast['Date'])"
      ],
      "metadata": {
        "id": "QUYw2m6Q_m5M"
      },
      "id": "QUYw2m6Q_m5M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25, 6))\n",
        "\n",
        "# Plot historical data\n",
        "plt.plot(historical_sales_df['OutDate'], historical_sales_df['TotalSales'], label='Actual Sales', color='blue')\n",
        "\n",
        "# Plot forecasted data\n",
        "plt.plot(total_forecast['Date'], total_forecast['Predicted Total Sales'], label='Forecasted Sales', color='red', linestyle='--')\n",
        "\n",
        "plt.title('Total Sales: Actual vs Forecasted')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9HLzO_5Z_mXu"
      },
      "id": "9HLzO_5Z_mXu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. Plot for Actual and Forecated for Sales Category"
      ],
      "metadata": {
        "id": "L_fAJaJOBOuT"
      },
      "id": "L_fAJaJOBOuT"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'OutDate' to datetime and sort\n",
        "historical_sales_by_category_df = sales_category_df\n",
        "historical_sales_by_category_df['OutDate'] = pd.to_datetime(historical_sales_by_category_df['OutDate'])\n",
        "historical_sales_by_category_df = historical_sales_by_category_df.sort_values('OutDate')"
      ],
      "metadata": {
        "id": "0RdmUA3DBPEV"
      },
      "id": "0RdmUA3DBPEV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_categories = historical_sales_by_category_df['Sales'].unique()\n",
        "\n",
        "# Set up the plot\n",
        "plt.figure(figsize=(25, 8))\n",
        "\n",
        "for category in sales_categories:\n",
        "    # Filter historical data for the category\n",
        "    historical_data = historical_sales_by_category_df[historical_sales_by_category_df['Sales'] == category]\n",
        "\n",
        "    # Filter forecasted data for the category\n",
        "    forecast_data = future_sales_predictions[category]\n",
        "\n",
        "    # Plot historical data\n",
        "    plt.plot(historical_data['OutDate'], historical_data['TotalSales'], label=f'Actual Sales - {category}')\n",
        "\n",
        "    # Plot forecasted data\n",
        "    plt.plot(forecast_data['Date'], forecast_data[f'Predicted Sales for {category}'], label=f'Forecasted Sales - {category}', linestyle='--')\n",
        "\n",
        "plt.title('Sales Category: Actual vs Forecasted')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Sales')\n",
        "\n",
        "# Place the legend below the plot\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), shadow=True, ncol=2)\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "SQVR9WcmBgSw"
      },
      "id": "SQVR9WcmBgSw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data to csv"
      ],
      "metadata": {
        "id": "ZBpaMNaMTsID"
      },
      "id": "ZBpaMNaMTsID"
    },
    {
      "cell_type": "code",
      "source": [
        "total_sales_df.to_csv('total_sales_df.csv')"
      ],
      "metadata": {
        "id": "l6s3NtymUFSP"
      },
      "id": "l6s3NtymUFSP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_forecast.to_csv('total_forecast.csv')"
      ],
      "metadata": {
        "id": "BB_Z3ftG_M18"
      },
      "id": "BB_Z3ftG_M18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historical_sales_by_category_df.to_csv('historical_sales_by_category_df.csv')"
      ],
      "metadata": {
        "id": "D2Gn0EW9TxUZ"
      },
      "id": "D2Gn0EW9TxUZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "future_sales_predictions.to_csv('future_sales_predictions.csv')"
      ],
      "metadata": {
        "id": "pT_DaawpTxHF"
      },
      "id": "pT_DaawpTxHF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "thdnB4_cTw2E"
      },
      "id": "thdnB4_cTw2E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc7b4c2a-1858-463b-865d-3acc3a5c03b3",
      "metadata": {
        "id": "fc7b4c2a-1858-463b-865d-3acc3a5c03b3"
      },
      "outputs": [],
      "source": [
        "# Group by Sales\n",
        "grouped_df = df.groupby(['OutDate', 'Sales']).agg({\n",
        "    'OutCountTotal': 'sum',\n",
        "    'TotalSales': 'sum',b\n",
        "    'TotalSales_LocalPrice': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "# grouped_df.set_index('OutDate', inplace=True)\n",
        "# grouped_df.sort_index(inplace=True)\n",
        "\n",
        "grouped_df['OutDate'] = pd.to_datetime(grouped_df['OutDate'])\n",
        "grouped_df.set_index('OutDate', inplace=True)\n",
        "\n",
        "grouped_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_df.dtypes"
      ],
      "metadata": {
        "id": "r1dZeWAyKzAJ"
      },
      "id": "r1dZeWAyKzAJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebec7b86-d128-4657-b59d-1afc9a37ad40",
      "metadata": {
        "id": "ebec7b86-d128-4657-b59d-1afc9a37ad40"
      },
      "outputs": [],
      "source": [
        "print(\"NaN values in the data:\", df.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99b1db1e-2846-49d6-b8a4-90bff0f951ef",
      "metadata": {
        "id": "99b1db1e-2846-49d6-b8a4-90bff0f951ef"
      },
      "outputs": [],
      "source": [
        "# # Define a split date as a Timestamp object\n",
        "# split_date = pd.Timestamp('2023-01-01')\n",
        "\n",
        "# # Perform the split without setting OutDate as index\n",
        "# train = grouped_df[grouped_df['OutDate'] < split_date]\n",
        "# test = grouped_df[grouped_df['OutDate'] >= split_date]\n",
        "\n",
        "# Splitting data into training and test sets\n",
        "train = grouped_df[grouped_df.index.year <= 2022]  # Data up to the end of 2022\n",
        "test = grouped_df[grouped_df.index.year == 2023]   # Data for 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f19825b3-f9fc-43d1-a83c-f1cc2db60d7c",
      "metadata": {
        "id": "f19825b3-f9fc-43d1-a83c-f1cc2db60d7c"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "403f816d-d310-4877-81cd-6ecf81ac9ef9",
      "metadata": {
        "id": "403f816d-d310-4877-81cd-6ecf81ac9ef9"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45700d02-ef60-4119-b510-fbd189ed0bef",
      "metadata": {
        "id": "45700d02-ef60-4119-b510-fbd189ed0bef"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "def diagnose_model(train_data, test_data, column_to_forecast):\n",
        "    # Fit the SARIMAX model\n",
        "    order = (1, 1, 1)  # ARIMA model hyperparameters\n",
        "    seasonal_order = (1, 1, 1, 12)  # Seasonal ARIMA model hyperparameters\n",
        "    model = SARIMAX(train_data[column_to_forecast], order=order, seasonal_order=seasonal_order)\n",
        "    results = model.fit()\n",
        "\n",
        "    # Display the model summary\n",
        "    print(results.summary())\n",
        "\n",
        "    # Check for stationarity\n",
        "    adf_test = adfuller(train_data[column_to_forecast])\n",
        "    print(f'ADF Statistic: {adf_test[0]}')\n",
        "    print(f'p-value: {adf_test[1]}')\n",
        "    for key, value in adf_test[4].items():\n",
        "        print('Critial Values:')\n",
        "        print(f'   {key}, {value}')\n",
        "\n",
        "    # Check if the forecast index has duplicates or irregularities\n",
        "    forecast_index = pd.date_range(start=train_data.index[-1], periods=len(test_data) + 1, freq='D')[1:]\n",
        "    print(\"\\nDuplicates in the forecast index:\", forecast_index.duplicated().any())\n",
        "    print(\"Forecast index type:\", forecast_index.dtype)\n",
        "\n",
        "# Perform the diagnostic for each of the specified columns\n",
        "for column in ['OutCountTotal', 'TotalSales', 'TotalSales_LocalPrice']:\n",
        "    diagnose_model(train, test, column)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdc0b016-74ba-487f-9dd2-a4ebdbc8ebb1",
      "metadata": {
        "id": "bdc0b016-74ba-487f-9dd2-a4ebdbc8ebb1"
      },
      "outputs": [],
      "source": [
        "def troubleshoot_forecast(train_data, test_data, column_to_forecast):\n",
        "    # Fit the SARIMAX model\n",
        "    order = (1, 1, 1)  # ARIMA model hyperparameters\n",
        "    seasonal_order = (1, 1, 1, 12)  # Seasonal ARIMA model hyperparameters\n",
        "    model = SARIMAX(train_data[column_to_forecast], order=order, seasonal_order=seasonal_order)\n",
        "    results = model.fit()\n",
        "\n",
        "    # Get the forecast\n",
        "    forecast = results.get_forecast(steps=len(test_data))\n",
        "    forecast_index = pd.date_range(start=train_data.index[-1], periods=len(test_data) + 1, freq='D')[1:]\n",
        "    forecast_df = pd.DataFrame(forecast.predicted_mean, index=forecast_index, columns=[f'Forecast_{column_to_forecast}'])\n",
        "\n",
        "    # Check for NaNs in forecast\n",
        "    print(f\"NaNs in forecast for {column_to_forecast}:\")\n",
        "    print(forecast_df.isna().sum())\n",
        "\n",
        "    # Verify forecast index\n",
        "    print(f\"\\nForecast index for {column_to_forecast}:\")\n",
        "    print(forecast_index)\n",
        "\n",
        "    # Verify test data index\n",
        "    print(f\"\\nTest data index for {column_to_forecast}:\")\n",
        "    print(test_data.index)\n",
        "\n",
        "# Perform troubleshooting for each of the specified columns\n",
        "for column in ['OutCountTotal', 'TotalSales', 'TotalSales_LocalPrice']:\n",
        "    troubleshoot_forecast(train, test, column)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "006e09d2-78c5-4758-9d3c-92965cc96159",
      "metadata": {
        "tags": [],
        "id": "006e09d2-78c5-4758-9d3c-92965cc96159"
      },
      "outputs": [],
      "source": [
        "def perform_forecast(train_data, test_data, column_to_forecast):\n",
        "    # Fit the SARIMAX model\n",
        "    order = (1, 1, 1)  # ARIMA model hyperparameters\n",
        "    seasonal_order = (1, 1, 1, 12)  # Seasonal ARIMA model hyperparameters\n",
        "    model = SARIMAX(train_data[column_to_forecast], order=order, seasonal_order=seasonal_order)\n",
        "    results = model.fit()\n",
        "\n",
        "    # Perform forecast\n",
        "    forecast = results.get_forecast(steps=len(test_data))\n",
        "    forecast_df = pd.DataFrame(forecast.predicted_mean, index=test_data.index, columns=[f'Forecast_{column_to_forecast}'])\n",
        "\n",
        "    # Ensure test_data has the same index as forecast_df for proper alignment\n",
        "    test_data = test_data.reindex(forecast_df.index)\n",
        "\n",
        "    # Drop any rows with NaN values in either the test data or the forecast\n",
        "    combined_df = pd.concat([test_data[column_to_forecast], forecast_df], axis=1).dropna()\n",
        "\n",
        "    # If combined_df is empty, there's an issue with the data alignment\n",
        "    if combined_df.empty:\n",
        "        raise ValueError(f\"No overlapping data to evaluate for column {column_to_forecast}\")\n",
        "\n",
        "    # Evaluate the forecast\n",
        "    mae = mean_absolute_error(combined_df[column_to_forecast], combined_df.iloc[:, 1])\n",
        "    print(f'Mean Absolute Error for {column_to_forecast}: {mae}')\n",
        "\n",
        "    # Plot the forecast against the actual values\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    train_data[column_to_forecast].plot(label='Train', legend=True)\n",
        "    combined_df[column_to_forecast].plot(label='Test', legend=True, alpha=0.7)\n",
        "    combined_df.iloc[:, 1].plot(label='Forecast', legend=True, color='red', alpha=0.7)\n",
        "\n",
        "    plt.title(f'Forecast vs Actuals for {column_to_forecast}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe3d724f-007e-40df-b27d-94ab541f2dbc",
      "metadata": {
        "id": "fe3d724f-007e-40df-b27d-94ab541f2dbc"
      },
      "outputs": [],
      "source": [
        "# Perform forecasting for each of the specified columns\n",
        "for column in ['OutCountTotal', 'TotalSales', 'TotalSales_LocalPrice']:\n",
        "    perform_forecast(train, test, column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7f71b73-b17e-4ddb-be59-b81745bb4fe8",
      "metadata": {
        "id": "d7f71b73-b17e-4ddb-be59-b81745bb4fe8"
      },
      "outputs": [],
      "source": [
        "def create_forecast_model(train_data, column_to_forecast, forecast_periods):\n",
        "    # Fit the SARIMAX model\n",
        "    order = (1, 1, 1)  # ARIMA model hyperparameters\n",
        "    seasonal_order = (1, 1, 1, 12)  # Seasonal ARIMA model hyperparameters\n",
        "    model = SARIMAX(train_data[column_to_forecast], order=order, seasonal_order=seasonal_order)\n",
        "    results = model.fit()\n",
        "\n",
        "    # Generate forecast\n",
        "    forecast = results.get_forecast(steps=forecast_periods)\n",
        "    forecast_index = pd.date_range(start=train_data.index[-1], periods=forecast_periods + 1, freq='D')[1:]\n",
        "    forecast_df = pd.DataFrame(forecast.predicted_mean, index=forecast_index, columns=[f'Forecast_{column_to_forecast}'])\n",
        "\n",
        "    return forecast_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b7b540-3bbc-4224-a753-261838e82666",
      "metadata": {
        "id": "f4b7b540-3bbc-4224-a753-261838e82666"
      },
      "outputs": [],
      "source": [
        "# Forecasting for each column\n",
        "forecast_periods = len(test)  # Number of periods in 2023 in your dataset\n",
        "forecasts = {}\n",
        "for column in ['OutCountTotal', 'TotalSales', 'TotalSales_LocalPrice']:\n",
        "    forecasts[column] = create_forecast_model(train, column, forecast_periods)\n",
        "\n",
        "# Accessing forecasted data\n",
        "outcount_forecast = forecasts['OutCountTotal']\n",
        "totalsales_forecast = forecasts['TotalSales']\n",
        "totalsales_localprice_forecast = forecasts['TotalSales_LocalPrice']\n",
        "\n",
        "print(outcount_forecast)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1faceb61-078f-44c6-b07b-d833f00e43e2",
      "metadata": {
        "id": "1faceb61-078f-44c6-b07b-d833f00e43e2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V7SCFFHG_Gu_"
      },
      "id": "V7SCFFHG_Gu_",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
